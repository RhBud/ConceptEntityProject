{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf56a5-2b53-432e-99c6-42bbfce43992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "DATABASE_NAME = \"umls\"                   # Your target database name\n",
    "COLLECTION_NAME = \"mrconso\"              # Your target collection name\n",
    "\n",
    "# File Settings\n",
    "# IMPORTANT: Update this to the correct path of your MRCONSO.RRF file!\n",
    "FILE_PATH = \"/pipeline_datalake/umls-2025AA-metathesaurus-full/2025AA/META/MRCONSO.RRF\"\n",
    "FILE_ENCODING = 'utf-8'  # Common encoding for UMLS files, adjust if necessary\n",
    "# If connecting from a Docker container to another Docker container named 'mongodb' (NO AUTHENTICATION):\n",
    "mongouser = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "mongopass = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "# Import Settings\n",
    "BATCH_SIZE = 10000  # Number of documents to insert in each batch\n",
    "DROP_COLLECTION_BEFORE_IMPORT = True # Set to False if you want to append to existing collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359b497-55a3-46f6-b200-80c433f1dca2",
   "metadata": {},
   "source": [
    "### Loading MRCONSO in mongo\n",
    "\n",
    "code from a previous personal project\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1aa8c2-325e-41c9-ab6b-96187ad359a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(f\"mongodb://{mongouser}:{mongopass}@mongodb:27017\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ad439-32f2-4d1a-bd8a-8f13efbba398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    # The ismaster command is cheap and does not require auth\n",
    "    client.admin.command('ismaster')\n",
    "    print(\"Successfully connected to MongoDB!\")\n",
    "    \n",
    "    # List all databases\n",
    "    print(\"\\nAvailable databases:\")\n",
    "    for db in client.list_database_names():\n",
    "        print(f\"- {db}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to MongoDB: {e}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601182c-1cf5-4cd2-b60a-ba3451e82779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "FIELD_NAMES = [\n",
    "    \"CUI\", \"LAT\", \"TS\", \"LUI\", \"STT\", \"SUI\", \"ISPREF\", \"AUI\",\n",
    "    \"SAUI\", \"SCUI\", \"SDUI\", \"SAB\", \"TTY\", \"CODE\", \"STR\",\n",
    "    \"SRL\", \"SUPPRESS\", \"CVF\"\n",
    "]\n",
    "\n",
    "\n",
    "def import_mrconso_to_mongodb():\n",
    "    \"\"\"\n",
    "    Reads the MRCONSO.RRF file and imports its content into MongoDB in batches.\n",
    "    \"\"\"\n",
    "    print(f\"Starting import of '{FILE_PATH}' into MongoDB '{DATABASE_NAME}.{COLLECTION_NAME}'\")\n",
    "\n",
    "    try:\n",
    "        # Ensure the MONGO_URI is correctly formatted.\n",
    "        # This print statement attempts to hide credentials if they were present in the URI.\n",
    "        \n",
    "        db = client[DATABASE_NAME]\n",
    "        collection = db[COLLECTION_NAME]\n",
    "        \n",
    "        # Ping the server to confirm connection.\n",
    "        # If auth is truly off, this should succeed. If auth is on, this might succeed anomymously\n",
    "        # but subsequent operations requiring auth will fail.\n",
    "        client.admin.command('ping')\n",
    "        print(f\"Successfully pinged MongoDB server.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting or pinging MongoDB: {e}\")\n",
    "        return\n",
    "\n",
    "    if DROP_COLLECTION_BEFORE_IMPORT:\n",
    "        try:\n",
    "            print(f\"Dropping existing collection '{COLLECTION_NAME}'...\")\n",
    "            collection.drop()\n",
    "            print(f\"Collection '{COLLECTION_NAME}' dropped.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error dropping collection: {e}\")\n",
    "            # If drop fails (e.g. due to auth if it's actually on), subsequent operations might also fail.\n",
    "\n",
    "    documents_batch = []\n",
    "    total_rows_processed = 0\n",
    "    total_rows_inserted = 0\n",
    "    batch_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(FILE_PATH):\n",
    "            print(f\"ERROR: File not found at '{FILE_PATH}'. Please check the path.\")\n",
    "            return\n",
    "\n",
    "        with open(FILE_PATH, 'r', encoding=FILE_ENCODING) as file:\n",
    "            reader = csv.reader(file, delimiter='|')\n",
    "            print(f\"Processing file. Batch size: {BATCH_SIZE} documents.\")\n",
    "\n",
    "            for row in reader:\n",
    "                total_rows_processed += 1\n",
    "\n",
    "                if len(row) < len(FIELD_NAMES):\n",
    "                    print(f\"Warning: Row {total_rows_processed} has only {len(row)} fields, expected {len(FIELD_NAMES)}. Skipping: {row}\")\n",
    "                    continue\n",
    "                \n",
    "                actual_row_data = row[:len(FIELD_NAMES)]\n",
    "                document = dict(zip(FIELD_NAMES, actual_row_data))\n",
    "                \n",
    "                documents_batch.append(document)\n",
    "\n",
    "                if len(documents_batch) >= BATCH_SIZE:\n",
    "                    try:\n",
    "                        collection.insert_many(documents_batch, ordered=False) # ordered=False can improve performance for large batches\n",
    "                        total_rows_inserted += len(documents_batch)\n",
    "                        batch_count += 1\n",
    "                        documents_batch = [] \n",
    "                        print(f\"Batch {batch_count} inserted. Total rows inserted: {total_rows_inserted}. Time: {time.time() - start_time:.2f}s\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error inserting batch: {e}\")\n",
    "                        # If auth error, further batches will also fail.\n",
    "\n",
    "            if documents_batch:\n",
    "                try:\n",
    "                    collection.insert_many(documents_batch, ordered=False)\n",
    "                    total_rows_inserted += len(documents_batch)\n",
    "                    batch_count += 1\n",
    "                    if batch_count % 10 == 0:\n",
    "                        print(f\"Final batch ({batch_count}) inserted. Total rows inserted: {total_rows_inserted}.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error inserting final batch: {e}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: File not found at '{FILE_PATH}'. Please check the path.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during file processing or insertion: {e}\")\n",
    "    finally:\n",
    "        if 'client' in locals() and client:\n",
    "            client.close()\n",
    "            print(\"MongoDB connection closed.\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n--- Import Summary ---\")\n",
    "    print(f\"Total rows processed from file: {total_rows_processed}\")\n",
    "    print(f\"Total rows successfully inserted into MongoDB: {total_rows_inserted}\")\n",
    "    print(f\"Total time taken: {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Import finished for '{DATABASE_NAME}.{COLLECTION_NAME}'.\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf30361-0fac-473d-9fcf-2f7772267e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_mrconso_to_mongodb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09a0ad-f368-4728-8ae4-1e4c5e0b25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update all documents to add 'str_lower' as lowercase of 'STR'\n",
    "result = collection.update_many(\n",
    "    {},\n",
    "    [\n",
    "        {\n",
    "            \"$set\": {\n",
    "                \"STR_LOWER\": { \"$toLower\": \"$STR\" }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Modified {result.modified_count} documents.\")\n",
    "\n",
    "# Create an index on the 'str_lower' field for faster lookups\n",
    "index_name = collection.create_index(\"STR_LOWER\")\n",
    "index_name = collection.create_index(\"STR\")\n",
    "\n",
    "print(f\"Created index: {index_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870a02f-50f9-4243-8dac-08a074e4e5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
