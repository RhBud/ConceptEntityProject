{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960a1cba-40f7-495b-b261-125130b6015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "from pymongo import MongoClient\n",
    "# imports for langchain and Chroma and plotly\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  environmental variables passed into service\n",
    "mongouser = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "mongopass = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
    "\n",
    "# Add these plus the key to the environmental variables\n",
    "client = MongoClient(f\"mongodb://{mongouser}:{mongopass}@mongodb:27017\")\n",
    "\n",
    "# key read in from env file at home on the local machine\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec958b1-0856-46a8-944c-77e785523013",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = pd.read_excel('/pipeline_datalake/List of clinical definitions lookups.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "243f67fd-c1e4-47f0-b8df-a8bc042b6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pd.read_excel('/pipeline_datalake/Annoted terms With Labels.xlsx', sheet_name='entity_clean', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6251a-1bb3-4c29-86a7-48ede76f4160",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This notebook contains the results for AI Engineer Candidate Assessment requirements 2 and 3\n",
    "\n",
    "2. Connect the application to one or more LLMs using industry standard methods (or be\n",
    "ready to explain why you chose to deviate from those standards)\n",
    "3. Develop an appropriate evaluation approach to identify errors and improve the promptâ€™s\n",
    "performance in generating accurate clinical definitions. Please show the results of your\n",
    "evaluation and what you changed as a result.\n",
    "\n",
    "#### Defined Rules for Correctness\n",
    "The key requirements is to \"generate accurate clinical definitions\"\n",
    "However due to the limitations of only using certain codes we are going to take a strict approach to this with emphasis on \"clinical definitions\"\n",
    "This model is NOT designed to say what code COULD represent -- especially if the vocabularies are too broad in that coding language\n",
    "Success will be measured also by recognizing the limitations in a certain vocabulary and if an \"accurate clinical definitions\" then to not answer\n",
    "\n",
    "Some entity type specific annotation rules\n",
    "1. diagnosis: ICD10 has major limitatoins in defining a specific medical concept. If the medical concept is too abstract for ICD10 a correct answer is a non answer\n",
    "2. medication: A drug ingredient should be result in only the RxNorm of the ingredient term, not all possible drugs that have that ingredient\n",
    "3. medication: A regime should result in all RxNorms of the regime active ingredients only\n",
    "4. drug_class: merely having an ATC representation does not make a concept a drug class in and of itself -- usually that is level 4 or higher\n",
    "5. procedure: Similar to diagnosis. If a term represents multiple procedures, multple CPT values should be returned\n",
    "6. measurements/labs: biomarkers and substances (that are not medicinal compounds) should return the avaliable tests\n",
    "\n",
    " changed as a result.\n",
    "\n",
    "#### Evaluation\n",
    "Based on the annotation from the defined rules above I will evaluate:\n",
    "- primarily entity type and code - together in one full score and separately\n",
    "- I will also evaluate text but not to the same degree - my thinking is that if the code is correct, this value can be looked up with a tool\n",
    "- I will also run a measure on the code differences just for good measure (like jaccard)\n",
    "- I will not kfold as my set is too small\n",
    "\n",
    "The evaluation is different from typical classification and is more in line with set thinking. So looping through the tidy output each entity will contribute along\n",
    "\n",
    "We will go a little basic and say a prediction but incorrect is FP. This will make our recall not a good metric to look at, but it will emphasize precision accuracy as our main metric\n",
    "\n",
    "Full entity level \n",
    "- Positive Prediction (P'): The LLM outputs any code for an entity.\n",
    "- Negative Prediction (N'): The LLM outputs no codes for an entity.    \n",
    "\n",
    "For the breakdown:\n",
    "- True Positive (TP): An entity that should have codes, and the LLM correctly provides \"Full Marks\" (all correct codes, no incorrect ones).\n",
    "- False Positive (FP): An entity should have no codes, but the LLM returns codes. An entity  should have codes, but the LLM returns incorrect codes (as a whole) or additional incorrect codes\n",
    "- True Negative (TN):  entity should have no codes, and  LLM correctly returns no codes\n",
    "- False Negative (FN): An entity that should have codes, but the LLM  returns no codes\n",
    "\n",
    "\n",
    "So each entity is contributing a full true/false negatives/positives overall in that line of thinking, and separately for entity type (as a whole) and code (as a whole)\n",
    "We will tally per entity\n",
    "\n",
    "And we do the same for entity alone and code alone\n",
    "and if we have time to do some jaccard or set measures we will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3b566d9e-fd6d-4923-a03b-5a7a0ea38e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 annotated validation concepts\n",
      "37 unique coded concepts expected\n"
     ]
    }
   ],
   "source": [
    "print(f\"{annotated_df['entity_name'].nunique()} annotated validation concepts\")\n",
    "print(f\"{annotated_df.shape[0]} unique coded concepts expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8b43855f-b561-4f8b-8efa-e5ee5f6a66a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_name</th>\n",
       "      <th>types</th>\n",
       "      <th>is_regime</th>\n",
       "      <th>set</th>\n",
       "      <th>should_say_no</th>\n",
       "      <th>codes_pipe</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>text</th>\n",
       "      <th>validated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liver Transplant Rejection</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T86.41</td>\n",
       "      <td>ICD-10</td>\n",
       "      <td>Liver transplant rejection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oseltamivir</td>\n",
       "      <td>medication</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260101</td>\n",
       "      <td>RxNorm</td>\n",
       "      <td>oseltamivir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lurbinectedin</td>\n",
       "      <td>medication</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2374729</td>\n",
       "      <td>RxNorm</td>\n",
       "      <td>lurbinectedin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheezing</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R06.2</td>\n",
       "      <td>ICD-10</td>\n",
       "      <td>Wheezing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eptifibatide</td>\n",
       "      <td>medication</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75635</td>\n",
       "      <td>RxNorm</td>\n",
       "      <td>eptifibatide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  entity_name       types is_regime  set should_say_no  \\\n",
       "0  Liver Transplant Rejection   diagnosis     False  val           NaN   \n",
       "1                 Oseltamivir  medication     False  val           NaN   \n",
       "2               Lurbinectedin  medication     False  val           NaN   \n",
       "3                    Wheezing   diagnosis     False  val           NaN   \n",
       "4                eptifibatide  medication     False  val           NaN   \n",
       "\n",
       "  codes_pipe vocabulary                        text validated  \n",
       "0     T86.41     ICD-10  Liver transplant rejection         1  \n",
       "1     260101     RxNorm                 oseltamivir         1  \n",
       "2    2374729     RxNorm               lurbinectedin         1  \n",
       "3      R06.2     ICD-10                    Wheezing         1  \n",
       "4      75635     RxNorm                eptifibatide         1  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0d37239-e553-44c8-a343-a33fc7dc468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_terms = annotated_df[['entity_name']].drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a65f2d92-01c6-46c7-bfed-f91f9f0171c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liver Transplant Rejection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oseltamivir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lurbinectedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheezing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eptifibatide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amoxicillin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>green nails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dilation of hypoglossal nerve, open approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Uric Acid (Urate)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alvimopan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Splenomegaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Covid-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dacarbazine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Methylxanthine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Alcohol induced pancreatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Abdominal Imaging (CT or MRI)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>H2 Receptor Antagonists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>long-acting beta agonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Census Subregion - Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>R-CHOP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     entity_name\n",
       "0                     Liver Transplant Rejection\n",
       "1                                    Oseltamivir\n",
       "2                                  Lurbinectedin\n",
       "3                                       Wheezing\n",
       "4                                   eptifibatide\n",
       "5                                    Amoxicillin\n",
       "6                                    green nails\n",
       "7   Dilation of hypoglossal nerve, open approach\n",
       "10                             Uric Acid (Urate)\n",
       "13                                     Alvimopan\n",
       "14                                  Splenomegaly\n",
       "15                                      Covid-19\n",
       "16                                   Dacarbazine\n",
       "17                                Methylxanthine\n",
       "19                  Alcohol induced pancreatitis\n",
       "21                 Abdominal Imaging (CT or MRI)\n",
       "23                       H2 Receptor Antagonists\n",
       "24                      long-acting beta agonist\n",
       "26                   Census Subregion - Mountain\n",
       "27                                        R-CHOP"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8a932-ba7c-45aa-9c98-b643d6f8cfbc",
   "metadata": {},
   "source": [
    "### Step 1) Run the default prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "461da71d-4cd1-4716-86f0-2d23a41fa7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmed from Jason, need to add a little bit of instructions to this (bare minimal) to also give the entity types\n",
    "\n",
    "def create_default_entity_prompt(concept_names_list):\n",
    "    '''Function attempts to automate prompt generation. This is likely more than we need but chatgpt isn't specifically design for medicine'''\n",
    "\n",
    "\n",
    "    entities_dict = {\n",
    "        \"entities\": concept_names_list\n",
    "    }\n",
    "\n",
    "    entity_json_string = json.dumps(entities_dict, indent=2)\n",
    "    # as little tweaking as possilbe\n",
    "    prompt = \"\"\"\n",
    "    You are an expert in medical coding logic. given the following json, return a json with the most appropriate medical codes for each concept, as well as the one or more types of entity.\n",
    "    \n",
    "    {\n",
    "      \"entities\": [\n",
    "        \"folfirinox\",\n",
    "        \"bismuth quadruple therapy\",\n",
    "        \"lung cancer\",\n",
    "        \"Lp(a) measurement\",\n",
    "        \"appendectomy\",\n",
    "        \"ACE inhibitors\"\n",
    "      ]\n",
    "    }\n",
    "    \n",
    "        \n",
    "    The allowable entity types you must assign are the exact strings:\n",
    "    * 'diagnosis'\n",
    "    * 'procedure' \n",
    "    * 'measurements/labs'\n",
    "    * 'medication'\n",
    "    * 'drug_class' \n",
    "    If more than one is correct, include both as one string separated by a comma\n",
    "\n",
    "    \n",
    "    The allowable code libraries are ICD-10 for diagnoses, ICD-10 category codes for groups of diagnoses, CPT for procedures, LOINC for measurements/labs, and RXnorm for medications, ATC for drug classes.\n",
    "    Each entity can have more than 1 code if applicable. For example, medication regimens should have a code per element.\n",
    "    For each code give a 0-100 score of your confidence in the accuracy of the code selected (100 is 100% confident). Do not include codes you are not very confident in. False positives are worse than false negatives.\n",
    "    \n",
    "    \n",
    "    Generate your response in the following format and only return the formatted JSON in the response\n",
    "    {\n",
    "    \"entities\": {\n",
    "    \"[ENTITY_NAME]\": {\n",
    "    \"entity_name\": \"[ENTITY_NAME]\",\n",
    "    \"types\": \"[ENTITY_TYPE]\",\n",
    "    \"codes\": [\n",
    "    {\n",
    "    \"code\": \"[CODE_VALUE]\",\n",
    "    \"system\": \"[CODE_SYSTEM]\",\n",
    "    \"description\": \"[HUMAN_READABLE_DESCRIPTION]\",\n",
    "    \"confidence\": [0-100]\n",
    "    }\n",
    "    ]\n",
    "    }\n",
    "    }\n",
    "\n",
    "    Here is the entity input json:\n",
    "\n",
    "    \"\"\"\n",
    "    prompt = prompt + entity_json_string\n",
    "    return prompt\n",
    "\n",
    "def flatten_entity_to_df(response_json):\n",
    "    '''Convert entity-type-only LLM output JSON to a DataFrame including regime flag.'''\n",
    "    \n",
    "        \n",
    "    records = []\n",
    "    \n",
    "    # Iterate through each entity in the 'entities' dictionary\n",
    "    for entity_key, entity_value in response_json['entities'].items():\n",
    "        entity_name = entity_value['entity_name']\n",
    "        entity_types = entity_value['types']\n",
    "    \n",
    "        for code_entry in entity_value['codes']:\n",
    "            record = {\n",
    "                'entity_name': entity_name,\n",
    "                'types': entity_types,\n",
    "                'code': code_entry.get('code'),  \n",
    "                'system': code_entry.get('system'),\n",
    "                'description': code_entry.get('description'),\n",
    "                'confidence': code_entry.get('confidence')\n",
    "            }\n",
    "            records.append(record)\n",
    "    \n",
    "    df_long_form_entities = pd.DataFrame(records)\n",
    "    return df_long_form_entities\n",
    "\n",
    "\n",
    "# standard completion function\n",
    "def get_completion(prompt, model=\"gpt-4-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    \n",
    "    return content\n",
    "# need to do this to process\n",
    "def strip_markdown_fences(text):\n",
    "    return re.sub(r\"^```json\\s*|```$\", \"\", text.strip(), flags=re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3157888-f0f1-4cb2-8173-1775e6e5e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "model=\"gpt-4-turbo\"\n",
    "\n",
    "\n",
    "   \n",
    "# this isn't relaly batching I'm just calling it that for right now. I didnt want to put the full list in at once\n",
    "all_raw_results = []\n",
    "for i in range(0, len(annotated_terms), batch_size):\n",
    "    batch_terms = annotated_terms[\"entity_name\"].iloc[i:i+batch_size].tolist()\n",
    "    prompt = create_default_entity_prompt(batch_terms)\n",
    "    response_json = get_completion(prompt, model=model)  # get raw JSON/dict\n",
    "    all_raw_results.append(response_json)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a821ebf6-31b1-4593-ab22-d10ef2919942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_full = pd.DataFrame()\n",
    "for ent in all_raw_results:\n",
    "    ent_clean = json.loads(strip_markdown_fences(ent))\n",
    "    df_clean = flatten_entity_to_df(ent_clean)\n",
    "    df_full = pd.concat([df_full, df_clean])\n",
    "\n",
    "df_full = df_full.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1345805d-e292-435d-bf6b-9629955595cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so only declined once\n",
    "len( list( set(df_full['entity_name'].to_list()) & set(annotated_terms['entity_name'].to_list()) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "059efad1-b96a-468e-859d-e9cf569ba98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_full[['entity_name','types','code','system','description','confidence']].copy() \\\n",
    "    .rename(columns={'types':'pred_type','code':'pred_code','system':'pred_vocab','description':'pred_text','confidence':'pred_confidence'})\n",
    "\n",
    "\n",
    "\n",
    "df_pred = annotated_terms[['entity_name']].drop_duplicates().merge(df_pred, on='entity_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b83a619-4738-4bf1-9a40-9890d90c5092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred['entity_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "930ac3cb-4894-4ed0-8f36-e90ff1fab7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['pred_no'] = df_pred['pred_type'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "df_pred['pred_confidence'] = df_pred['pred_confidence'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "89b088a5-a69b-4d62-8441-cc227b849a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_name</th>\n",
       "      <th>pred_type</th>\n",
       "      <th>pred_code</th>\n",
       "      <th>pred_vocab</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>pred_confidence</th>\n",
       "      <th>pred_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liver Transplant Rejection</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>T86.42</td>\n",
       "      <td>ICD-10</td>\n",
       "      <td>Liver transplant rejection</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oseltamivir</td>\n",
       "      <td>medication</td>\n",
       "      <td>84989</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Oseltamivir</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lurbinectedin</td>\n",
       "      <td>medication</td>\n",
       "      <td>2363736</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Lurbinectedin</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheezing</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>R06.2</td>\n",
       "      <td>ICD-10</td>\n",
       "      <td>Wheezing</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eptifibatide</td>\n",
       "      <td>medication</td>\n",
       "      <td>35623</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Eptifibatide</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amoxicillin</td>\n",
       "      <td>medication</td>\n",
       "      <td>723</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Amoxicillin</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>green nails</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>L60.8</td>\n",
       "      <td>ICD-10</td>\n",
       "      <td>Other nail disorders</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dilation of hypoglossal nerve, open approach</td>\n",
       "      <td>procedure</td>\n",
       "      <td>04V03DZ</td>\n",
       "      <td>ICD-10-PCS</td>\n",
       "      <td>Dilation of Hypoglossal Nerve, Open Approach</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Uric Acid (Urate)</td>\n",
       "      <td>measurements/labs</td>\n",
       "      <td>3084-1</td>\n",
       "      <td>LOINC</td>\n",
       "      <td>Uric acid [Mass/volume] in Serum or Plasma</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alvimopan</td>\n",
       "      <td>medication</td>\n",
       "      <td>544725</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Alvimopan</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Splenomegaly</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>R16.1</td>\n",
       "      <td>ICD-10</td>\n",
       "      <td>Splenomegaly, not elsewhere classified</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Covid-19</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>U07.1</td>\n",
       "      <td>ICD-10</td>\n",
       "      <td>COVID-19, virus identified</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dacarbazine</td>\n",
       "      <td>medication</td>\n",
       "      <td>1798</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Dacarbazine</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Methylxanthine</td>\n",
       "      <td>drug_class</td>\n",
       "      <td>R03DA</td>\n",
       "      <td>ATC</td>\n",
       "      <td>Methylxanthines</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Alcohol induced pancreatitis</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>K85.2</td>\n",
       "      <td>ICD-10</td>\n",
       "      <td>Alcohol-induced acute pancreatitis</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alcohol induced pancreatitis</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>K86.0</td>\n",
       "      <td>ICD-10</td>\n",
       "      <td>Alcohol-induced chronic pancreatitis</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Abdominal Imaging (CT or MRI)</td>\n",
       "      <td>procedure</td>\n",
       "      <td>74150</td>\n",
       "      <td>CPT</td>\n",
       "      <td>CT abdomen without contrast</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Abdominal Imaging (CT or MRI)</td>\n",
       "      <td>procedure</td>\n",
       "      <td>74160</td>\n",
       "      <td>CPT</td>\n",
       "      <td>CT abdomen with contrast</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Abdominal Imaging (CT or MRI)</td>\n",
       "      <td>procedure</td>\n",
       "      <td>74170</td>\n",
       "      <td>CPT</td>\n",
       "      <td>CT abdomen without &amp; with contrast</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Abdominal Imaging (CT or MRI)</td>\n",
       "      <td>procedure</td>\n",
       "      <td>74181</td>\n",
       "      <td>CPT</td>\n",
       "      <td>MRI abdomen without contrast</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Abdominal Imaging (CT or MRI)</td>\n",
       "      <td>procedure</td>\n",
       "      <td>74182</td>\n",
       "      <td>CPT</td>\n",
       "      <td>MRI abdomen with contrast</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Abdominal Imaging (CT or MRI)</td>\n",
       "      <td>procedure</td>\n",
       "      <td>74183</td>\n",
       "      <td>CPT</td>\n",
       "      <td>MRI abdomen without &amp; with contrast</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>H2 Receptor Antagonists</td>\n",
       "      <td>drug_class</td>\n",
       "      <td>A02BA</td>\n",
       "      <td>ATC</td>\n",
       "      <td>H2-receptor antagonists</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>long-acting beta agonist</td>\n",
       "      <td>drug_class</td>\n",
       "      <td>R03AC</td>\n",
       "      <td>ATC</td>\n",
       "      <td>Long-acting beta-2 agonists</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Census Subregion - Mountain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>R-CHOP</td>\n",
       "      <td>medication</td>\n",
       "      <td>205855</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Rituximab</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>R-CHOP</td>\n",
       "      <td>medication</td>\n",
       "      <td>1797510</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Cyclophosphamide</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>R-CHOP</td>\n",
       "      <td>medication</td>\n",
       "      <td>1797511</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Doxorubicin</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>R-CHOP</td>\n",
       "      <td>medication</td>\n",
       "      <td>1797512</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Vincristine</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>R-CHOP</td>\n",
       "      <td>medication</td>\n",
       "      <td>1797513</td>\n",
       "      <td>RXnorm</td>\n",
       "      <td>Prednisone</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     entity_name          pred_type pred_code  \\\n",
       "0                     Liver Transplant Rejection          diagnosis    T86.42   \n",
       "1                                    Oseltamivir         medication     84989   \n",
       "2                                  Lurbinectedin         medication   2363736   \n",
       "3                                       Wheezing          diagnosis     R06.2   \n",
       "4                                   eptifibatide         medication     35623   \n",
       "5                                    Amoxicillin         medication       723   \n",
       "6                                    green nails          diagnosis     L60.8   \n",
       "7   Dilation of hypoglossal nerve, open approach          procedure   04V03DZ   \n",
       "8                              Uric Acid (Urate)  measurements/labs    3084-1   \n",
       "9                                      Alvimopan         medication    544725   \n",
       "10                                  Splenomegaly          diagnosis     R16.1   \n",
       "11                                      Covid-19          diagnosis     U07.1   \n",
       "12                                   Dacarbazine         medication      1798   \n",
       "13                                Methylxanthine         drug_class     R03DA   \n",
       "14                  Alcohol induced pancreatitis          diagnosis     K85.2   \n",
       "15                  Alcohol induced pancreatitis          diagnosis     K86.0   \n",
       "16                 Abdominal Imaging (CT or MRI)          procedure     74150   \n",
       "17                 Abdominal Imaging (CT or MRI)          procedure     74160   \n",
       "18                 Abdominal Imaging (CT or MRI)          procedure     74170   \n",
       "19                 Abdominal Imaging (CT or MRI)          procedure     74181   \n",
       "20                 Abdominal Imaging (CT or MRI)          procedure     74182   \n",
       "21                 Abdominal Imaging (CT or MRI)          procedure     74183   \n",
       "22                       H2 Receptor Antagonists         drug_class     A02BA   \n",
       "23                      long-acting beta agonist         drug_class     R03AC   \n",
       "24                   Census Subregion - Mountain                NaN       NaN   \n",
       "25                                        R-CHOP         medication    205855   \n",
       "26                                        R-CHOP         medication   1797510   \n",
       "27                                        R-CHOP         medication   1797511   \n",
       "28                                        R-CHOP         medication   1797512   \n",
       "29                                        R-CHOP         medication   1797513   \n",
       "\n",
       "    pred_vocab                                     pred_text  pred_confidence  \\\n",
       "0       ICD-10                    Liver transplant rejection             95.0   \n",
       "1       RXnorm                                   Oseltamivir             98.0   \n",
       "2       RXnorm                                 Lurbinectedin             98.0   \n",
       "3       ICD-10                                      Wheezing             95.0   \n",
       "4       RXnorm                                  Eptifibatide             98.0   \n",
       "5       RXnorm                                   Amoxicillin             98.0   \n",
       "6       ICD-10                          Other nail disorders             80.0   \n",
       "7   ICD-10-PCS  Dilation of Hypoglossal Nerve, Open Approach             90.0   \n",
       "8        LOINC    Uric acid [Mass/volume] in Serum or Plasma             95.0   \n",
       "9       RXnorm                                     Alvimopan             98.0   \n",
       "10      ICD-10        Splenomegaly, not elsewhere classified             95.0   \n",
       "11      ICD-10                    COVID-19, virus identified            100.0   \n",
       "12      RXnorm                                   Dacarbazine            100.0   \n",
       "13         ATC                               Methylxanthines             90.0   \n",
       "14      ICD-10            Alcohol-induced acute pancreatitis             95.0   \n",
       "15      ICD-10          Alcohol-induced chronic pancreatitis             95.0   \n",
       "16         CPT                   CT abdomen without contrast             90.0   \n",
       "17         CPT                      CT abdomen with contrast             90.0   \n",
       "18         CPT            CT abdomen without & with contrast             90.0   \n",
       "19         CPT                  MRI abdomen without contrast             90.0   \n",
       "20         CPT                     MRI abdomen with contrast             90.0   \n",
       "21         CPT           MRI abdomen without & with contrast             90.0   \n",
       "22         ATC                       H2-receptor antagonists             95.0   \n",
       "23         ATC                   Long-acting beta-2 agonists             95.0   \n",
       "24         NaN                                           NaN              0.0   \n",
       "25      RXnorm                                     Rituximab             90.0   \n",
       "26      RXnorm                              Cyclophosphamide             90.0   \n",
       "27      RXnorm                                   Doxorubicin             90.0   \n",
       "28      RXnorm                                   Vincristine             90.0   \n",
       "29      RXnorm                                    Prednisone             90.0   \n",
       "\n",
       "    pred_no  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  \n",
       "7         0  \n",
       "8         0  \n",
       "9         0  \n",
       "10        0  \n",
       "11        0  \n",
       "12        0  \n",
       "13        0  \n",
       "14        0  \n",
       "15        0  \n",
       "16        0  \n",
       "17        0  \n",
       "18        0  \n",
       "19        0  \n",
       "20        0  \n",
       "21        0  \n",
       "22        0  \n",
       "23        0  \n",
       "24        1  \n",
       "25        0  \n",
       "26        0  \n",
       "27        0  \n",
       "28        0  \n",
       "29        0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "343704d8-fe23-435a-9df5-85b7caa9b690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_terms['entity_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1a8f5aa4-efb5-45e1-b27c-55b6841f7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df = annotated_df[['entity_name','types','codes_pipe','vocabulary','text','should_say_no']] \\\n",
    "    .rename(columns={'types':'true_type','should_say_no':'true_no','codes_pipe':'true_code','vocabulary':'true_vocab','text':'true_text'})\n",
    "\n",
    "truth_df['true_no'] = truth_df['true_no'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "baf965e4-4c1d-4355-8a49-b1c6a866c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in truth_df[list(truth_df.columns)[:-1]]:\n",
    "    truth_df[col] = truth_df[col].str.strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27ea76-ecee-4250-99af-475f4b998e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7f7fc9ac-4439-4ebb-9f12-7db34bd69a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_base = truth_df[['entity_name']].drop_duplicates().copy()\n",
    "\n",
    "for index, row in score_base.iterrows():\n",
    "    # outputs we want are tallys of\n",
    "    entity_name = row['entity_name']\n",
    "    tmp_truth = truth_df[truth_df['entity_name'] == entity_name].copy()\n",
    "    tmp_pred = pred_df[pred_df['entity_name'] == entity_name].copy()\n",
    "\n",
    "    # if this is 1 then I reviewed and said this would not be a possible definition for the vocabularies\n",
    "    # if ttrue_code_sethis is 0 then it is possible\n",
    "    true_negative = int(tmp_truth['true_no'].max())\n",
    "    # if this is 1 then the model decline to answer with a possible definition for the vocabularies\n",
    "    # if this is 0 then it answered\n",
    "    pred_negative = int(tmp_pred['pred_no'].max())\n",
    "    \n",
    "    # create for easy set math\n",
    "    if true_negative == 1:\n",
    "        true_entity_set = set()\n",
    "        true_code_set = set()\n",
    "        true_text_set =  set()\n",
    "    else:\n",
    "        true_entity_set = set(tmp_truth['true_type'].to_list())\n",
    "        true_code_set = set(tmp_truth['true_code'].to_list())\n",
    "        true_text_set = set(tmp_truth['true_text'].to_list())\n",
    "    if pred_negative == 1:\n",
    "        pred_entity_set = set()\n",
    "        pred_code_set = set()\n",
    "        pred_text_set = set()\n",
    "\n",
    "    else:\n",
    "        pred_entity_set = set(tmp_pred['pred_type'].to_list())\n",
    "        pred_code_set = set(tmp_pred['pred_code'].to_list())\n",
    "        pred_text_set = set(tmp_pred['pred_text'].to_list())\n",
    "\n",
    "\n",
    "    pred_text_set = set([c.lower() for c in list(pred_text_set)])\n",
    "    true_text_set = set([c.lower() for c in list(true_text_set)])\n",
    "\n",
    "    if len(true_entity_set) == 0 and len(pred_entity_set) == 0:\n",
    "        entity_res = 'tn' \n",
    "    elif true_entity_set == pred_entity_set:\n",
    "        entity_res = 'tp'\n",
    "    elif len(true_code_set) > 0 and len(pred_entity_set) == 0:\n",
    "        entity_res = 'fn' \n",
    "    else:\n",
    "        # the key decision here was this -- which I had to think about for a while\n",
    "        entity_res = 'fp' \n",
    "    \n",
    "    if len(true_code_set) == 0 and len(pred_code_set) == 0:\n",
    "        code_res = 'tn' \n",
    "    elif true_code_set == pred_code_set:\n",
    "        code_res = 'tp'\n",
    "    elif len(true_code_set) > 0 and len(pred_code_set) == 0:\n",
    "        code_res = 'fn' \n",
    "    else:\n",
    "        code_res = 'fp' \n",
    "\n",
    "    if len(true_text_set) == 0 and len(pred_text_set) == 0:\n",
    "        text_res = 'tn' \n",
    "    elif true_text_set == pred_text_set:\n",
    "        text_res = 'tp'\n",
    "    elif len(true_text_set) > 0 and len(pred_text_set) == 0:\n",
    "        text_res = 'fn' \n",
    "    else:\n",
    "        text_res = 'fp' \n",
    "        \n",
    "\n",
    "    score_base.loc[index,'true_no'] = true_negative\n",
    "    score_base.loc[index,'pred_no'] = pred_negative\n",
    "\n",
    "    score_base.loc[index,'entity_eval'] = entity_res\n",
    "    score_base.loc[index,'code_eval'] = code_res\n",
    "    score_base.loc[index,'text_eval'] = text_res\n",
    "    \n",
    "    score_base.at[index,'entity_pred_set'] = pred_entity_set\n",
    "    score_base.at[index,'entity_true_set'] = true_entity_set\n",
    "    \n",
    "    \n",
    "    score_base.at[index,'code_pred_set'] = pred_code_set\n",
    "    score_base.at[index,'code_true_set'] = true_code_set\n",
    "\n",
    "    score_base.at[index,'text_pred_set'] = pred_text_set\n",
    "    score_base.at[index,'text_true_set'] = true_text_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55fbf91-e12f-4cbb-b94b-f38969ce7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full cleaned comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "022e1083-8389-4f16-9e6e-6721cf86f769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_name</th>\n",
       "      <th>true_no</th>\n",
       "      <th>pred_no</th>\n",
       "      <th>entity_eval</th>\n",
       "      <th>code_eval</th>\n",
       "      <th>text_eval</th>\n",
       "      <th>entity_pred_set</th>\n",
       "      <th>entity_true_set</th>\n",
       "      <th>code_pred_set</th>\n",
       "      <th>code_true_set</th>\n",
       "      <th>text_pred_set</th>\n",
       "      <th>text_true_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liver Transplant Rejection</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{T86.42}</td>\n",
       "      <td>{T86.41}</td>\n",
       "      <td>{liver transplant rejection}</td>\n",
       "      <td>{liver transplant rejection}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oseltamivir</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{84989}</td>\n",
       "      <td>{260101}</td>\n",
       "      <td>{oseltamivir}</td>\n",
       "      <td>{oseltamivir}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lurbinectedin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{2363736}</td>\n",
       "      <td>{2374729}</td>\n",
       "      <td>{lurbinectedin}</td>\n",
       "      <td>{lurbinectedin}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheezing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{R06.2}</td>\n",
       "      <td>{R06.2}</td>\n",
       "      <td>{wheezing}</td>\n",
       "      <td>{wheezing}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eptifibatide</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{35623}</td>\n",
       "      <td>{75635}</td>\n",
       "      <td>{eptifibatide}</td>\n",
       "      <td>{eptifibatide}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amoxicillin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{723}</td>\n",
       "      <td>{723}</td>\n",
       "      <td>{amoxicillin}</td>\n",
       "      <td>{amoxicillin}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>green nails</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{L60.8}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{other nail disorders}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dilation of hypoglossal nerve, open approach</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>{procedure}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{04V03DZ}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{dilation of hypoglossal nerve, open approach}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Uric Acid (Urate)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>{measurements/labs}</td>\n",
       "      <td>{measurements/labs}</td>\n",
       "      <td>{3084-1}</td>\n",
       "      <td>{3084-4, 3087-7, 3084-1, 2916-2}</td>\n",
       "      <td>{uric acid [mass/volume] in serum or plasma}</td>\n",
       "      <td>{uric acid [mass/volume] in blood, uric acid [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Alvimopan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{544725}</td>\n",
       "      <td>{480639}</td>\n",
       "      <td>{alvimopan}</td>\n",
       "      <td>{alvimopan}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Splenomegaly</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{R16.1}</td>\n",
       "      <td>{R16.1}</td>\n",
       "      <td>{splenomegaly, not elsewhere classified}</td>\n",
       "      <td>{splenomegaly nos}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Covid-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{U07.1}</td>\n",
       "      <td>{U07.1}</td>\n",
       "      <td>{covid-19, virus identified}</td>\n",
       "      <td>{covid-19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dacarbazine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{1798}</td>\n",
       "      <td>{3098}</td>\n",
       "      <td>{dacarbazine}</td>\n",
       "      <td>{dacarbazine}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Methylxanthine</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>{drug_class}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{R03DA}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{methylxanthines}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alcohol induced pancreatitis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{diagnosis}</td>\n",
       "      <td>{K86.0, K85.2}</td>\n",
       "      <td>{K85.20, K86.0}</td>\n",
       "      <td>{alcohol-induced acute pancreatitis, alcohol-i...</td>\n",
       "      <td>{alcohol induced acute pancreatitis without ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Abdominal Imaging (CT or MRI)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>{procedure}</td>\n",
       "      <td>{procedure}</td>\n",
       "      <td>{74182, 74183, 74150, 74160, 74170, 74181}</td>\n",
       "      <td>{74182, 74183, 74150, 74160, 74170, 74181}</td>\n",
       "      <td>{mri abdomen without contrast, ct abdomen with...</td>\n",
       "      <td>{mri of abdomen with contrast, mri scan of abd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>H2 Receptor Antagonists</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{drug_class}</td>\n",
       "      <td>{drug_class}</td>\n",
       "      <td>{A02BA}</td>\n",
       "      <td>{A02BA}</td>\n",
       "      <td>{h2-receptor antagonists}</td>\n",
       "      <td>{h2-receptor antagonists}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>long-acting beta agonist</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>{drug_class}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{R03AC}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{long-acting beta-2 agonists}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Census Subregion - Mountain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tn</td>\n",
       "      <td>tn</td>\n",
       "      <td>tn</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>R-CHOP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{medication}</td>\n",
       "      <td>{1797513, 1797510, 205855, 1797512, 1797511}</td>\n",
       "      <td>{11202, 3002, 8640, 121191, 3639}</td>\n",
       "      <td>{cyclophosphamide, vincristine, prednisone, ri...</td>\n",
       "      <td>{cyclophosphamide, vincristine, prednisone, ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     entity_name  true_no  pred_no  \\\n",
       "0                     Liver Transplant Rejection      0.0      0.0   \n",
       "1                                    Oseltamivir      0.0      0.0   \n",
       "2                                  Lurbinectedin      0.0      0.0   \n",
       "3                                       Wheezing      0.0      0.0   \n",
       "4                                   eptifibatide      0.0      0.0   \n",
       "5                                    Amoxicillin      0.0      0.0   \n",
       "6                                    green nails      1.0      0.0   \n",
       "7   Dilation of hypoglossal nerve, open approach      1.0      0.0   \n",
       "10                             Uric Acid (Urate)      0.0      0.0   \n",
       "14                                     Alvimopan      0.0      0.0   \n",
       "15                                  Splenomegaly      0.0      0.0   \n",
       "16                                      Covid-19      0.0      0.0   \n",
       "17                                   Dacarbazine      0.0      0.0   \n",
       "18                                Methylxanthine      1.0      0.0   \n",
       "20                  Alcohol induced pancreatitis      0.0      0.0   \n",
       "22                 Abdominal Imaging (CT or MRI)      0.0      0.0   \n",
       "28                       H2 Receptor Antagonists      0.0      0.0   \n",
       "29                      long-acting beta agonist      1.0      0.0   \n",
       "31                   Census Subregion - Mountain      1.0      1.0   \n",
       "32                                        R-CHOP      0.0      0.0   \n",
       "\n",
       "   entity_eval code_eval text_eval      entity_pred_set      entity_true_set  \\\n",
       "0           tp        fp        tp          {diagnosis}          {diagnosis}   \n",
       "1           tp        fp        tp         {medication}         {medication}   \n",
       "2           tp        fp        tp         {medication}         {medication}   \n",
       "3           tp        tp        tp          {diagnosis}          {diagnosis}   \n",
       "4           tp        fp        tp         {medication}         {medication}   \n",
       "5           tp        tp        tp         {medication}         {medication}   \n",
       "6           fp        fp        fp          {diagnosis}                   {}   \n",
       "7           fp        fp        fp          {procedure}                   {}   \n",
       "10          tp        fp        fp  {measurements/labs}  {measurements/labs}   \n",
       "14          tp        fp        tp         {medication}         {medication}   \n",
       "15          tp        tp        fp          {diagnosis}          {diagnosis}   \n",
       "16          tp        tp        fp          {diagnosis}          {diagnosis}   \n",
       "17          tp        fp        tp         {medication}         {medication}   \n",
       "18          fp        fp        fp         {drug_class}                   {}   \n",
       "20          tp        fp        fp          {diagnosis}          {diagnosis}   \n",
       "22          tp        tp        fp          {procedure}          {procedure}   \n",
       "28          tp        tp        tp         {drug_class}         {drug_class}   \n",
       "29          fp        fp        fp         {drug_class}                   {}   \n",
       "31          tn        tn        tn                   {}                   {}   \n",
       "32          tp        fp        tp         {medication}         {medication}   \n",
       "\n",
       "                                   code_pred_set  \\\n",
       "0                                       {T86.42}   \n",
       "1                                        {84989}   \n",
       "2                                      {2363736}   \n",
       "3                                        {R06.2}   \n",
       "4                                        {35623}   \n",
       "5                                          {723}   \n",
       "6                                        {L60.8}   \n",
       "7                                      {04V03DZ}   \n",
       "10                                      {3084-1}   \n",
       "14                                      {544725}   \n",
       "15                                       {R16.1}   \n",
       "16                                       {U07.1}   \n",
       "17                                        {1798}   \n",
       "18                                       {R03DA}   \n",
       "20                                {K86.0, K85.2}   \n",
       "22    {74182, 74183, 74150, 74160, 74170, 74181}   \n",
       "28                                       {A02BA}   \n",
       "29                                       {R03AC}   \n",
       "31                                            {}   \n",
       "32  {1797513, 1797510, 205855, 1797512, 1797511}   \n",
       "\n",
       "                                 code_true_set  \\\n",
       "0                                     {T86.41}   \n",
       "1                                     {260101}   \n",
       "2                                    {2374729}   \n",
       "3                                      {R06.2}   \n",
       "4                                      {75635}   \n",
       "5                                        {723}   \n",
       "6                                           {}   \n",
       "7                                           {}   \n",
       "10            {3084-4, 3087-7, 3084-1, 2916-2}   \n",
       "14                                    {480639}   \n",
       "15                                     {R16.1}   \n",
       "16                                     {U07.1}   \n",
       "17                                      {3098}   \n",
       "18                                          {}   \n",
       "20                             {K85.20, K86.0}   \n",
       "22  {74182, 74183, 74150, 74160, 74170, 74181}   \n",
       "28                                     {A02BA}   \n",
       "29                                          {}   \n",
       "31                                          {}   \n",
       "32           {11202, 3002, 8640, 121191, 3639}   \n",
       "\n",
       "                                        text_pred_set  \\\n",
       "0                        {liver transplant rejection}   \n",
       "1                                       {oseltamivir}   \n",
       "2                                     {lurbinectedin}   \n",
       "3                                          {wheezing}   \n",
       "4                                      {eptifibatide}   \n",
       "5                                       {amoxicillin}   \n",
       "6                              {other nail disorders}   \n",
       "7      {dilation of hypoglossal nerve, open approach}   \n",
       "10       {uric acid [mass/volume] in serum or plasma}   \n",
       "14                                        {alvimopan}   \n",
       "15           {splenomegaly, not elsewhere classified}   \n",
       "16                       {covid-19, virus identified}   \n",
       "17                                      {dacarbazine}   \n",
       "18                                  {methylxanthines}   \n",
       "20  {alcohol-induced acute pancreatitis, alcohol-i...   \n",
       "22  {mri abdomen without contrast, ct abdomen with...   \n",
       "28                          {h2-receptor antagonists}   \n",
       "29                      {long-acting beta-2 agonists}   \n",
       "31                                                 {}   \n",
       "32  {cyclophosphamide, vincristine, prednisone, ri...   \n",
       "\n",
       "                                        text_true_set  \n",
       "0                        {liver transplant rejection}  \n",
       "1                                       {oseltamivir}  \n",
       "2                                     {lurbinectedin}  \n",
       "3                                          {wheezing}  \n",
       "4                                      {eptifibatide}  \n",
       "5                                       {amoxicillin}  \n",
       "6                                                  {}  \n",
       "7                                                  {}  \n",
       "10  {uric acid [mass/volume] in blood, uric acid [...  \n",
       "14                                        {alvimopan}  \n",
       "15                                 {splenomegaly nos}  \n",
       "16                                         {covid-19}  \n",
       "17                                      {dacarbazine}  \n",
       "18                                                 {}  \n",
       "20  {alcohol induced acute pancreatitis without ne...  \n",
       "22  {mri of abdomen with contrast, mri scan of abd...  \n",
       "28                          {h2-receptor antagonists}  \n",
       "29                                                 {}  \n",
       "31                                                 {}  \n",
       "32  {cyclophosphamide, vincristine, prednisone, ri...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124fba7-abd5-4cd3-ac07-b0d23354b4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4c5d26ac-0582-43e1-9514-e0de788ebffe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "91097129-0f6a-4789-8a24-836a8e019d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_excel('/pipeline_datalake/clean_default_predictions.xlsx',index=False)\n",
    "truth_df.to_excel('/pipeline_datalake/clean_annotations.xlsx',index=False)\n",
    "score_base.to_excel('/pipeline_datalake/clean_default_model_eval.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "13a027db-2953-4023-82eb-73e09d03398b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_confidence\n",
       "90.0     13\n",
       "95.0      8\n",
       "98.0      5\n",
       "100.0     2\n",
       "80.0      1\n",
       "0.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred['pred_confidence'].value_counts()\n",
    "# does not lack confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ea3b5-5f04-4494-ba2a-71f703c8d6a9",
   "metadata": {},
   "source": [
    "I am a little concerned about my annotation of text, multiple sources (athena and UMLS) may have different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e431ec3c-4460-4e2c-aa09-b733bf749323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Evaluation Metrics: {'counts': {'tp': 15, 'fp': 4, 'tn': 1}, 'precision': 0.789, 'f1': 0.882}\n",
      "\n",
      "Code Evaluation Metrics: {'counts': {'fp': 13, 'tp': 6, 'tn': 1}, 'precision': 0.316, 'f1': 0.48}\n",
      "\n",
      "Text Evaluation Metrics: {'counts': {'tp': 10, 'fp': 9, 'tn': 1}, 'precision': 0.526, 'f1': 0.69}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# we do not get as good coverage\n",
    "# but this is more straightforward\n",
    "def get_eval_metrics(df, column):\n",
    "    y_true = df[column].apply(lambda x: 1 if x in ['tp','fn'] else 0)\n",
    "    y_pred = df[column].apply(lambda x: 1 if x in ['tp','fp'] else 0)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    f1        = f1_score(y_true, y_pred, zero_division=0)\n",
    "    counts    = df[column].value_counts().to_dict()\n",
    "\n",
    "    return {\n",
    "        'counts':    counts,\n",
    "        'precision': round(precision, 3),\n",
    "        'f1':        round(f1,        3)\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "entity_metrics = get_eval_metrics(score_base, 'entity_eval')\n",
    "code_metrics = get_eval_metrics(score_base, 'code_eval')\n",
    "text_metrics = get_eval_metrics(score_base, 'text_eval')\n",
    "\n",
    "print(\"Entity Evaluation Metrics:\", entity_metrics)\n",
    "print()\n",
    "print(\"Code Evaluation Metrics:\", code_metrics)\n",
    "print()\n",
    "print(\"Text Evaluation Metrics:\", text_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f4ced9f3-b8db-4351-ac36-2a1686bb2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity+Code Precision-first Metrics: {'counts': {'fp': 13, 'tp': 6, 'tn': 1}, 'precision': 0.316, 'f1': 0.48}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, f1_score\n",
    "\n",
    "def make_entity_code_label(row):\n",
    "    ent = row['entity_eval']  # 'tp', 'fp', 'fn', or 'tn'\n",
    "    code = row['code_eval']   # 'tp', 'fp', 'fn', or 'tn'\n",
    "\n",
    "    #True Negative\n",
    "    if ent == 'tn' and code == 'tn':\n",
    "        return 'tn'\n",
    "\n",
    "    #True Positive\n",
    "    if ent != 'tn' and code == 'tp':\n",
    "        return 'tp'\n",
    "\n",
    "    #False Negative \n",
    "    if ent != 'tn' and code == 'tn':\n",
    "        return 'fn'\n",
    "\n",
    "    # basically when the codes are not perfect\n",
    "    return 'fp'\n",
    "\n",
    "score_base['entity_code_eval'] = score_base.apply(make_entity_code_label, axis=1)\n",
    "\n",
    "# same\n",
    "y_true = score_base['entity_code_eval'].map(lambda x: 1 if x in ['tp','fn'] else 0)\n",
    "y_pred = score_base['entity_code_eval'].map(lambda x: 1 if x in ['tp','fp'] else 0)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "f1        = f1_score(       y_true, y_pred, zero_division=0)\n",
    "counts    = score_base['entity_code_eval'].value_counts().to_dict()\n",
    "\n",
    "print(\"Entity+Code Precision-first Metrics:\", {\n",
    "    'counts':    counts,\n",
    "    'precision': round(precision, 3),\n",
    "    'f1':        round(f1,        3)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ffce5-69b4-4fec-b5fd-43e672fbef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically the overall kind of becomes the code level prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "32c4c4af-db75-4234-80d0-2a6d65a1faf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Jaccard Score: 0.379\n"
     ]
    }
   ],
   "source": [
    "def compute_jaccard(row):\n",
    "    pred = row['code_pred_set']\n",
    "    truth = row['code_true_set']\n",
    "    if isinstance(pred, set) and isinstance(truth, set):\n",
    "        union = pred | truth\n",
    "        intersection = pred & truth\n",
    "        return len(intersection) / len(union) if union else 1.0\n",
    "    return 0\n",
    "\n",
    "score_base['jaccard'] = score_base.apply(compute_jaccard, axis=1)\n",
    "print(\"Mean Jaccard Score:\", round(score_base['jaccard'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87eaf18-3cce-455b-bf27-652151236c0d",
   "metadata": {},
   "source": [
    "Corrections made:\n",
    "- add 3084-1 to truth for Uric Acid (Urate)\n",
    "- 85.2}is more appropriate for Alcohol induced pancreatitis than 85.20\n",
    "- 74182, 74183, 74150, 74160, 74170, 74181 is the right combination for Abdominal Imaging (CT or MRI)\n",
    "- A02BA is correct for H2 Receptor Antagonists\n",
    "- Athena and UMLS may display different text names so I may have messed some of those up\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411cd1df-fb51-45a3-af81-35c62217a249",
   "metadata": {},
   "source": [
    "## Review of results and plans for improvement\n",
    "- We do not do kfold its too small, plus not tuning here, plus doing entity-level + code-level + jaccard\n",
    "- High recall is not impressive really because over predictive behavior resulting in many fps\n",
    "\n",
    "Entity:\n",
    "- Precision looks mediocre but when we look at only cases where the model SHOULD have guess at all, it has perfect precision\n",
    "- Maybe do not need to adjust into a separate call but rather focus on it deciding when to not guess at all\n",
    "  \n",
    "Code:\n",
    "- Terrible precision but this eval method punishes.\n",
    "- Jaccard however confirms poor judgement when coding\n",
    "- Reviewing the codes we see a lot of wrong drug codes that dont make any sense\n",
    "- I may try and specify more about ingredients -- they are often just named woith the same name as their corresponding concept even\n",
    "- specify to not use other vocabularies - used a ICD10PCS\n",
    "- specify what a non clinical mapping looks like, think of an example for the prompt with a rare disease not being compatible wtih icd10 and that a no guess is better\n",
    "  \n",
    "Tet \n",
    "- For drugs when it is incorrect in the code it looks like it is just repeating the text from the input\n",
    "- Text is inconsistent but also I am using both athena and UMLS and there are a few cases where I may have use confusing version\n",
    "- In general I am not going to focus on addressing this in the prompt. If I get the code correct that should be easy to do a lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da74a1-1f87-44d3-b3d1-047c77d7f2be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
